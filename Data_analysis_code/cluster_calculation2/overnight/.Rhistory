#We also compare the performance of the cor.sim function below, which calls on cor_sim_function.cpp, rather then the one completely written in C++.  Since the last step amounts to dividing two doubles, there is no real difference as detected by microbenchmark.
cor.sim <- function(X, Y) {
num <- dot_product2(X,Y) #this is neccessary as we are only computing the dot product of the lower trangular matrix.
denom <- sqrt(dot_product2(X,X)- num.row)*sqrt(dot_product2(Y,Y))
return (num/denom)
}
############################################################################################
############################################################################################
# a function to pick my n subsamples:
Df.subsample <-function(Df, n.subsample, ratio.subsample){
#Data.frame is the binarized dataframe, we assume that a function already created an ID column
#n.subsample is the number of subsamples
#size.subsample is the size of the subsample given in percentage.
#Errors
if (ratio.subsample > 1) stop("Please give subsample size in terms of ratio of the total size.")
if (n.subsample < 0) stop("n.subsample negative value: invalid.")
if (ratio.subsample < 0) stop("ratio.subsample negative value: invalid.")
foreach(i=1:n.subsample) %dopar% {
set.seed(i)
sample_frac(Df, size = ratio.subsample, replace = FALSE) #sample rows of dataframe without replacement
}
}
############################################################################################
############################################################################################
k.means <- function(Df, k, num.samples, ratio.subsample){
list.subsamples <- Df.subsample(Df, num.samples, ratio.subsample)
foreach(j=1:num.samples)%dopar%{ #I will calculate kmeans for each of the num.samples number of subsamples.
#I will use my Df.subsample function to obtain a list of dataframes of subsamples of the ratio.subsample size:
#each item in the list is a dataframe
set.seed(j)
subsample <- list.subsamples[[j]] #the jth element of this list is the jth subsample dataframe
k.means <- kmeans(subsample[7:ncol(Df)],centers = k, nstart=40, iter.max=5000) #this was hardcoded in since the lingBinarize dataset's questions start on column 7 to the last ncol(Df), and this is the same for its subsamples
k.means <- k.means$cluster #this step extracts the cluster vector from the kmeans() output k.means$cluster.
k.means <- as.data.frame(k.means) #we need to use semi_joins so coerce into a dataframe, the rownames will still carry the ids of the subsamples.
k.means$ID <- as.numeric(rownames(k.means)) #it's hard to semi_join by rownames, so I will create a new column called ID that copies the rownames info
k.means
}
}
############################################################################################
############################################################################################
k.stabalize <- function(Df, k, num.samples, ratio.subsample){
list <- k.means(Df, k, num.samples, ratio.subsample)
#correlationSim <- list()
foreach(m=1:length(list), .combine = "c") %:% # we loops through all unique pairs (order does not matter since cor.sim(X,Y)=cor.sim(Y,X))
foreach(l=1:m) %dopar% {  #note that we need only look up to m-1 since we don't want to compare the same elements of the list (so m != l)
subsample1 <- arrange(semi_join(list[[m]], list[[l]], by= "ID"), ID) #this restricts our attention to common points of list[[m]] and list[[l]].  The semi_join means subsample1 only has cluster info for b[[m]]
subsample2 <- arrange(semi_join(list[[l]], list[[m]], by= "ID"), ID) #this will consider clusters in b[[l]], for common points of list[[m]] and list[[l]]
#now we apply the cluster.adjacency() to subsample1 and subsample2, outputting two matrices we can feed into cor.sim() (this will be fast since I wrote the forloops of both functions in C++)
cor.sim(X,Y)
#recall that correlationSim is a list defined for each k from 1 to k.max, so this is the list of n^2-n pairs (n number of subsamples) for which we have a similiarty measure
}
}
############################################################################################
############################################################################################
nCores <- 4#as.numeric(Sys.getenv('NSLOTS')) #QUESTIONS, for the SCF clusters, how many cores can I use? should I use?
registerDoParallel(nCores)
k.max = 3
Df <- lingBinary[1:30,1:30]
number.samples =5
ratio.sub = 0.8
# i need to remember to delete the 1 correlations from each iteration
#there will be a diagonal number of 1s.
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
k.stabalize(Df, 2, number.samples, ratio.sub)
k.stabalize <- function(Df, k, num.samples, ratio.subsample){
list <- k.means(Df, k, num.samples, ratio.subsample)
#correlationSim <- list()
foreach(m=1:length(list), .combine = "c") %:% # we loops through all unique pairs (order does not matter since cor.sim(X,Y)=cor.sim(Y,X))
foreach(l=1:m) %dopar% {  #note that we need only look up to m-1 since we don't want to compare the same elements of the list (so m != l)
subsample1 <- arrange(semi_join(list[[m]], list[[l]], by= "ID"), ID) #this restricts our attention to common points of list[[m]] and list[[l]].  The semi_join means subsample1 only has cluster info for b[[m]]
subsample2 <- arrange(semi_join(list[[l]], list[[m]], by= "ID"), ID) #this will consider clusters in b[[l]], for common points of list[[m]] and list[[l]]
#now we apply the cluster.adjacency() to subsample1 and subsample2, outputting two matrices we can feed into cor.sim() (this will be fast since I wrote the forloops of both functions in C++)
cor.sim(subsample1,subsample2)
#recall that correlationSim is a list defined for each k from 1 to k.max, so this is the list of n^2-n pairs (n number of subsamples) for which we have a similiarty measure
}
}
############################################################################################
############################################################################################
nCores <- 4#as.numeric(Sys.getenv('NSLOTS')) #QUESTIONS, for the SCF clusters, how many cores can I use? should I use?
registerDoParallel(nCores)
k.max = 3
Df <- lingBinary[1:30,1:30]
number.samples =5
ratio.sub = 0.8
# i need to remember to delete the 1 correlations from each iteration
#there will be a diagonal number of 1s.
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
cor.sim <- function(X, Y) {
num <- dot_product2(X,Y) #this is neccessary as we are only computing the dot product of the lower trangular matrix.
denom <- sqrt(dot_product2(X,X))*sqrt(dot_product2(Y,Y))
return (num/denom)
}
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
k.stabalize(Df, 2, number.samples, ratio.sub)
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
print(data.list)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
parallel.results
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
return data.list
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
data.list
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
parallel.results
k.stabalize(Df, 2, number.samples, ratio.sub)
number.samples =10
ratio.sub = 0.8
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
data.list
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
parallel.results
parallel.results[1]
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
k.stabalize(Df, i, number.samples, ratio.sub)
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
parallel.results
parallel3.csv
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
k.stabalize(Df, i, number.samples, ratio.sub)
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
k.max = 5
parallel.results <- foreach(i = 1:k.max) %dopar% { #will specify k.max
# Make sure that each process has its own random number stream.
data.list <- k.stabalize(Df, i, number.samples, ratio.sub)
filename <- sprintf("parallel%d.csv", i)
write.csv(data.list, file=filename, quote=F, row.names=F)
return(filename)
}
parallel4 <-read.csv(file="parallel4.csv")
library('Rcpp')
library('microbenchmark')
library('dplyr')
library(foreach)
require(doParallel)
require(parallel)
library(iterators)
paralell4 <-tbl_df(parallel4)
parallel4
ncol(parallel4)
parallel4 <-read.csv(file="parallel4.csv", head=T)
paralell4 <-tbl_df(parallel4)
paralell4
?read.csv()
parallel4 <-read.csv(file="parallel4.csv", header=TRUE)
parallel4 <-tbl_df(parallel4)
parallel4
parallel4 <-read.csv(file="parallel4.csv", header=TRUE)
parallel4 <-tbl_df(parallel4)
parallel4
working.directory <- file.path("~/Desktop/215A/lab3")
parallel4 <-read.csv(file="parallel4.csv")
parallel4 <-tbl_df(parallel4)
parallel4
parallel4 <-read.csv(file="parallel4.csv")
parallel4
parallel4 <-read.csv(file="parallel4.csv", sep=" ")
parallel4
parallel4 <-read.table(file="parallel4.xls", sep=" ")
parallel4 <-read.table(file="parallel4.xls")
parallel4 <-read.table(file="parallel4.xls", sep="")
parallel4 <-read.table(file="parallel4.csv", sep="")
parallel4
parallel4 <-read.table(file="parallel4.csv", header=F)
parallel4
parallel4 <-read.table(file="parallel4.csv", header=F, sep="")
parallel4
parallel4 <-read.table(file="parallel4.csv", header=F, sep="\s")
parallel4 <-read.csv(file="parallel4.csv", header=F, sep="")
parallel4
library(ggplot)
library(dplyr)
library(ggplot2)
working.directory <- file.path("~/Documents/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))
setwd(working.directory)
setwd(working.directory)
setwd(working.directory)
library(ggplot2)
library(dplyr)
working.directory <- file.path("~/Documents/cluster2/overnight")
setwd(working.directory)
working.directory <- file.path("/Users/LishaLi/Desktop/Documents/cluster")
working.directory <- file.path("/Users/LishaLi/Desktop/Documents/cluster2/overnight")
setwd(working.directory)
setwd("/Users/LishaLi/Desktop/Documents/cluster2/overnight")
setwd("/Users/LishaLi/Desktop/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))
work1.csv
work12.csv
class(work12.csv)
for (i in 1:length(temp)) assign(temp[i], as.matrix(temp[i]))
is.matrix(work12.csv)
?upperTriangle()
library(gdata)
install.packages("gdata")
library(gdata)
?upperTriangle()
upperTriangle(work12.csv)
x <- matrix( 1:25, nrow=5, ncol=5)
x
upperTriangle(x)
upperTriangle(x, diag=TRUE)
work12.csv
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i]))
upperTriangle(work12.csv)
class(upperTriangle(work12.csv))
temp
temp[[2]]
temp[1]
list.df <- lapply(ls(), function(x) if (class(get(x)) == "data.frame") get(x))
list.df
list.df[[1]]
list.df[[3]]
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
list(ls(pattern='work*')) #get list of dataframes
list.df <- list(ls(pattern='work*')) #get list of dataframes
list.df
list.df[[4]]
list.df[4
]
list.df[2]
length(list.df)
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
lapply(names(l.df), function(x) upperTriangle(l.df[[x]], "y", x)) #extracting upper triangular list
l.df
length(l.df)
colnames(l.df)
names(l.df)
l.df[-1] <- NULL
names(l.df)
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
lapply(names(l.df), function(x) upperTriangle(l.df[[x]],"y" x)) #extracting upper triangular list
library(gdata)
lapply(names(l.df), function(x) upperTriangle(l.df[[x]],"y" x)) #extracting upper triangular list
(names(l.df)
)
lapply(names(l.df), function(x) upperTriangle(l.df[[x]]])) #extracting upper triangular list
lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
class(freq)
class(freq[[1]])
length(freq[[1]])
20^2-20
/2
library(ggplot2)
plot.d <- as.data.frame(cbind(freq))
plot.d
geom_histogram()
?geom_histogram()
ggplot()+geom_histogram(freq[1])
ggplot()+geom_histogram(data=freq[1])
as.data.frame(freq)
length(list)
length(freq)
freq[length(freq)]
freq <- freq[1:12]
freq <- as.data.frame(freq)
freq
names(freq)
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq[length(freq)]
freq <- freq[1:12]
names(freq)
freq[2]
names(l.df)
names(freq) <- names(l.df)[1:12]
freq
freq <- as.data.frame(freq)
freq
freq <-tbl_df(freq)
freq
ggplot(freq)+geom_histogram(freq$work10.csv)
ggplot(freq)+geom_histogram(aes=freq[[work10.csv]])
ggplot(freq)+geom_histogram(aes=freq[work10.csv])
class(freq)
ggplot(freq, aes(x=work10.csv))+geom_histogram()
names(freq)
library(reshape)
d <- melt(freq[1:12])
d <- melt(freq[,-c(1:12)])
head(diamonds)
g <- melt(diamonds[,-c(2:4)])
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram()
diamonds
diamonds <-tbl_df(diamonds)
diamonds
ggplot(g,aes(x = value)) +
facet_wrap(~variable,scales = "free_x") +
geom_histogram()
d <- melt(freq[,-(1:12)])
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram()
g[variable]
g[[variable]]
ggplot(d, aes(x=value))+facet_wrap(~column)+geom_histogram()
d
d <- melt(freq[,(1:12)])
d
head(d)
ggplot(d, aes(x=value))+facet_wrap(~column)+geom_histogram()
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram()
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 10)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.001)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.01)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.1)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.01)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.05)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.02)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.015)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.05)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.005)
ggplot(d, aes(x=value))+facet_wrap(~variable)+geom_histogram(binwidth = 0.015)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.015)
working.directory <- file.path("/Users/LishaLi/Desktop/cluster2/overnight")
setwd("/Users/LishaLi/Desktop/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq[length(freq)]
freq <- freq[1:12]
names(freq) <- names(l.df)[1:12]
freq <- as.data.frame(freq)
freq <-tbl_df(freq)
names(freq)
freq[8]
?sample()
sample <- sample(freq[8], 190, replace = FALSE)
class(freq(8))
class(freq[8])
length(freq[8])
freq[8]
length(freq[8])
ncol(freq[8])
length(freq[[8]])
sample <- sample(freq[[8]], 190, replace = FALSE)
freq[[8]] <- sample
freq <- as.data.frame(freq)
freq <-tbl_df(freq)
d <- melt(freq[,(1:12)])
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.015)
working.directory <- file.path("/Users/LishaLi/Desktop/cluster2/overnight")
setwd("/Users/LishaLi/Desktop/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq[length(freq)]
freq <- freq[1:length(freq)-1]
names(freq) <- names(l.df)[1:length(freq)-1]
freq <- as.data.frame(freq)
library(ggplot2)
library(dplyr)
library(gdata)
library(reshape)
working.directory <- file.path("/Users/LishaLi/Desktop/cluster2/overnight")
setwd("/Users/LishaLi/Desktop/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq[length(freq)]
freq <- freq[1:length(freq)-1]
names(freq) <- names(l.df)[1:length(freq)-1]
freq <- as.data.frame(freq)
names(freq)
working.directory <- file.path("/Users/LishaLi/Desktop/cluster2/overnight")
setwd("/Users/LishaLi/Desktop/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
names(freq)
l.df
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq
names(freq)
names(l.df)
working.directory <- file.path("/Users/LishaLi/Desktop/cluster2/overnight")
setwd("/Users/LishaLi/Desktop/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
names(l.df)
freq <- freq[6:length(freq)-1]
names(freq) <- names(l.df)[6:length(freq)-1]
freq <- as.data.frame(freq)
names(freq)
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
names(l.df)
freq <- freq[c("work2.csv", "work3.csv", "work4.csv", "work5.csv", "work6.csv", "work7.csv", "work8.csv", "work9.csv")]
names(freq) <- c("work2.csv", "work3.csv", "work4.csv", "work5.csv", "work6.csv", "work7.csv", "work8.csv", "work9.csv")
freq <- as.data.frame(freq)
length(freq)
freq
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq <- freq[["work2.csv", "work3.csv", "work4.csv", "work5.csv", "work6.csv", "work7.csv", "work8.csv", "work9.csv"]]
freq <- freq[("work2.csv", "work3.csv", "work4.csv", "work5.csv", "work6.csv", "work7.csv", "work8.csv", "work9.csv")]
freq <- freq[c("work2.csv", "work3.csv", "work4.csv", "work5.csv", "work6.csv", "work7.csv", "work8.csv", "work9.csv")]
freq
freq <- freq[[c("work2.csv", "work3.csv", "work4.csv", "work5.csv", "work6.csv", "work7.csv", "work8.csv", "work9.csv")]]
library(ggplot2)
library(dplyr)
library(gdata)
library(reshape)
working.directory <- file.path("/Users/LishaLi/Desktop/cluster2/overnight")
setwd("/Users/LishaLi/Desktop/cluster2/overnight")
temp = list.files(pattern="*.csv")
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq[length(freq)]
for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i])) #reading all csv files
l.df <- setNames(lapply(ls(pattern="work"), function(x) get(x)), ls(pattern="work")) #get list of dataframes
l.df
freq <- lapply(names(l.df), function(x) upperTriangle(l.df[[x]])) #extracting upper triangular list
freq
freq[length(freq)]
freq <- freq[1:length(freq)-1]
names(freq) <- names(l.df)[1:length(freq)-1]
freq <- as.data.frame(freq)
freq[[1]]
freq <-tbl_df(freq)
length(freq[[1]])
d <- melt(freq[,(1:12)])
names(freq)
freq[[8]]
names(freq)[8]
names(freq)[8] <- "work9.csv"
names(freq)
d <- melt(freq[,(1:length(freq))])
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.015)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.015)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.01)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.008)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.0001)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.001)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.0014)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_density()
?geom_density()
ggplot(d, aes(x=log(value)))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.0014)
ggplot(d, aes(x=log(value)))+facet_wrap(~variable, ncol=2)+geom_density()
ggplot(d, aes(x=exp(value)))+facet_wrap(~variable, ncol=2)+geom_density()
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.0014)
ggplot(d, aes(x=value))+facet_wrap(~variable, ncol=2)+geom_histogram(binwidth = 0.002)
